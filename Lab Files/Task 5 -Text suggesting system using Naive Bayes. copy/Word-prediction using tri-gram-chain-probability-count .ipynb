{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOor3xVWndfihoXODtJN0z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maruf520/Artificial-Intelligence-Lab/blob/main/Word-prediction%20using%20tri-gram-chain-probability-count%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRHJcXcBqiQE"
      },
      "source": [
        "import nltk\r\n",
        "from nltk import bigrams, trigrams\r\n",
        "from collections import Counter, defaultdict\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCW32YiTql96",
        "outputId": "33525f29-f7ca-4b21-d170-032ea261e006"
      },
      "source": [
        "nltk.download('reuters')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O9YlBtFqoGw"
      },
      "source": [
        "from nltk.corpus import reuters\r\n",
        "def tryToLower(u):\r\n",
        "  if type(u)==str:\r\n",
        "    return u.lower()\r\n",
        "  return u"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-8iGtPkqrC3"
      },
      "source": [
        "# Create a placeholder for model\r\n",
        "model1 = defaultdict(lambda: 0)\r\n",
        "model2 = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "model3 = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "model4 = defaultdict(lambda: set())\r\n",
        "model5 = defaultdict(lambda: set())\r\n",
        "\r\n",
        "total_word=0\r\n",
        "\r\n",
        "# Count frequency of co-occurance  \r\n",
        "for sentence in reuters.sents():\r\n",
        "  for word in sentence:\r\n",
        "    model1[word]+=1\r\n",
        "    total_word+=1\r\n",
        "  for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "    w1=tryToLower(w1)\r\n",
        "    w2=tryToLower(w2)\r\n",
        "    w3=tryToLower(w3)\r\n",
        "    model2[w3][w2] += 1\r\n",
        "    model3[w3][w1] += 1\r\n",
        "    model4[w2].add(w3)\r\n",
        "    model5[w1].add(w3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMniM9a3q3vb"
      },
      "source": [
        "def calculateProbablities(model):\r\n",
        "  for wNext in model:\r\n",
        "    total_count = float(sum(model[wNext].values()))\r\n",
        "    for wPrev in model[wNext]:\r\n",
        "        model[wNext][wPrev] /= total_count"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HzyFf5Tq64J"
      },
      "source": [
        "calculateProbablities(model2)\r\n",
        "calculateProbablities(model3)\r\n",
        "\r\n",
        "for word in model1:\r\n",
        "  model1[word] /=total_word"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2WNx0w8q9Fa"
      },
      "source": [
        "def calculateTrigramProbabilityChain(w1,w2,w3):\r\n",
        "  return model1[w3]*model2[w3][w2]*model3[w3][w1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ_nWlMuq_qY",
        "outputId": "86ae5fe3-51eb-474f-e6d7-2e0cec47cd97"
      },
      "source": [
        "best10=[]\r\n",
        "def trigramSuggestions(w1,w2):\r\n",
        "  for w3 in model4[w2] & model5[w1]:\r\n",
        "    sc=calculateTrigramProbabilityChain(w1,w2,w3)\r\n",
        "    # print(wNext,sc)\r\n",
        "    best10.append((w3,sc))\r\n",
        "\r\n",
        "trigramSuggestions('this','is')\r\n",
        "best10.sort(key=lambda o: o[1],reverse=True)\r\n",
        "print(*best10[:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('not', 1.4807434758670995e-06) ('due', 9.287062083948189e-07) ('expected', 8.017113195705539e-07) ('a', 7.12241730296221e-07) ('amore', 5.810855491578036e-07) ('likely', 4.55780658247161e-07) ('going', 4.4431597720133996e-07) ('now', 3.6627114930279654e-07) ('to', 3.546577864798332e-07) ('unlikely', 3.3777278863311074e-07)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3HQqel5rB9V"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}